<h1 align="center">There are many like it, but this one is mine.</h1> 

Various excellent open-source Large Language Model(LLM) repositories are available as of Feb 2024. This repository learns and pulls from all these great repositories to reimplement different LLM-related techniques and concepts to understand them.  

Additionally, this is open-source, so that I can share it with the broader community.
This repository organizes different implementations across different branches and does not strive to share code across these branches. The focus is on the techniques and concepts using simple code, not enhancing code reuse and supporting many different use cases in a single codebase. However, each branch strives to be well-designed.

| Branch Name | Description | Status |
| ----------- | ----------- | ------ |
| [old_2022](https://github.com/appliedml42/LLMs/tree/old_2023)   | Early exploration of training Billion+ parameters LLMs using FDSP | Inactive |
| [microsoft/phi](https://github.com/appliedml42/LLMs/tree/microsoft/phi) | Exploration of SFT and DPO on Small Language Models using microsoft/phi | Active|

# References
* [Github:nanoGPT](https://github.com/karpathy/nanoGPT)
* [Github:lit-gpt](https://github.com/Lightning-AI/lit-gpt)
* [Github:TinyLlama](https://github.com/jzhang38/TinyLlama)
* [Pytorch Blog:Accelerating LLM Inference in Pure Pytorch](https://pytorch.org/blog/accelerating-generative-ai-2)
