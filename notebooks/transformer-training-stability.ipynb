{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMTb+KZsonE7YEztekYZz3D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appliedml42/language-modeling/blob/main/notebooks/transformer-training-stability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_V7kVCUXa8rA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn import LayerNorm, Linear, Dropout\n",
        "from torch.nn.functional import binary_cross_entropy_with_logits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = {}\n",
        "norms = {}\n",
        "parameters = {}\n",
        "for i in range(1):\n",
        "  #transforms[f'transform_{i}'] = Linear(1, 1)\n",
        "  #parameters[f't_{i}'] = list(transforms[f'transform_{i}'].parameters())\n",
        "\n",
        "  norms[f'norm_{i}'] = LayerNorm(1)\n",
        "  parameters[f'norm_{i}'] = list(norms[f'norm_{i}'].parameters())\n",
        "\n",
        "#print(transforms)\n",
        "print(norms)\n",
        "print(parameters)"
      ],
      "metadata": {
        "id": "01eDTukdUQjZ",
        "outputId": "ef7a12ea-18de-41a7-beca-48c43b2387fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'norm_0': LayerNorm((1,), eps=1e-05, elementwise_affine=True)}\n",
            "{'norm_0': [Parameter containing:\n",
            "tensor([1.], requires_grad=True), Parameter containing:\n",
            "tensor([0.], requires_grad=True)]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  x = torch.rand(1)\n",
        "  print('input:', x) \n",
        "  for i in range(1):\n",
        "    x = norms[f'norm_{i}'](x)\n",
        "\n",
        "  print('output:', x)\n",
        "  x.backward()\n",
        "  \n",
        "  for module, params in parameters.items():\n",
        "    print('Value', module, [x.grad for x in params])\n",
        "  \n",
        "  for module, params in parameters.items():\n",
        "    print('Grad', module, [x.grad for x in params])\n",
        "  print()"
      ],
      "metadata": {
        "id": "bggFCzpRMS4o",
        "outputId": "2c96ac98-26f2-4778-f1d9-15f62fea5c83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: tensor([0.8610])\n",
            "output: tensor([-5.8552e-06], grad_fn=<NativeLayerNormBackward0>)\n",
            "norm_0\n",
            "[tensor([-5.8552e-06]), tensor([1.])]\n",
            "\n",
            "input: tensor([0.9547])\n",
            "output: tensor([-5.8482e-06], grad_fn=<NativeLayerNormBackward0>)\n",
            "norm_0\n",
            "[tensor([-1.1703e-05]), tensor([2.])]\n",
            "\n",
            "input: tensor([0.1523])\n",
            "output: tensor([8.4440e-07], grad_fn=<NativeLayerNormBackward0>)\n",
            "norm_0\n",
            "[tensor([-1.0859e-05]), tensor([3.])]\n",
            "\n",
            "input: tensor([0.9412])\n",
            "output: tensor([9.3236e-07], grad_fn=<NativeLayerNormBackward0>)\n",
            "norm_0\n",
            "[tensor([-9.9266e-06]), tensor([4.])]\n",
            "\n",
            "input: tensor([0.7798])\n",
            "output: tensor([1.6073e-06], grad_fn=<NativeLayerNormBackward0>)\n",
            "norm_0\n",
            "[tensor([-8.3193e-06]), tensor([5.])]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  x = torch.rand(1)\n",
        "  print('input:', x) \n",
        "  for i in range(1):\n",
        "    x = norms[f'norm_{i}'](x)\n",
        "    print(list(parameters[f'transform_{i}'].parameters()))\n",
        "  \n",
        "  print('output:', x)\n",
        "  x.backward()\n",
        " \n",
        "  for module, params in parameters.items():\n",
        "    print(module)\n",
        "    print([x.grad for x in params])\n",
        "  print()"
      ],
      "metadata": {
        "id": "YPstjF1PcSE3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}