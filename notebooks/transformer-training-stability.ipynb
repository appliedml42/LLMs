{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNvatzjsq2hjl9zvGem4rcy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/appliedml42/language-modeling/blob/main/notebooks/transformer-training-stability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_V7kVCUXa8rA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn import LayerNorm, Linear, Dropout\n",
        "from torch.nn.functional import binary_cross_entropy_with_logits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = {}\n",
        "norms = {}\n",
        "parameters = {}\n",
        "for i in range(1):\n",
        "  #transforms[f'transform_{i}'] = Linear(1, 1)\n",
        "  #parameters[f't_{i}'] = list(transforms[f'transform_{i}'].parameters())\n",
        "\n",
        "  norms[f'norm_{i}'] = LayerNorm(1)\n",
        "  parameters[f'norm_{i}'] = list(norms[f'norm_{i}'].parameters())\n",
        "\n",
        "#print(transforms)\n",
        "print(norms)\n",
        "print(parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01eDTukdUQjZ",
        "outputId": "f3e2c6ac-36a7-4c02-9dbc-753a616ff018"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'norm_0': LayerNorm((1,), eps=1e-05, elementwise_affine=True)}\n",
            "{'norm_0': [Parameter containing:\n",
            "tensor([1.], requires_grad=True), Parameter containing:\n",
            "tensor([0.], requires_grad=True)]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  x = torch.rand(1)\n",
        "  print('input:', x) \n",
        "  for i in range(1):\n",
        "    x = norms[f'norm_{i}'](x)\n",
        "    print(norms[f'norm_{i}'].eps)\n",
        "\n",
        "  print('output:', x)\n",
        "  x.backward()\n",
        "  \n",
        "  for module, params in parameters.items():\n",
        "    print('Value', module, [x.data for x in params])\n",
        "  \n",
        "  for module, params in parameters.items():\n",
        "    print('Grad', module, [x.grad for x in params])\n",
        "  print()\n",
        "\n",
        "  for module, params in parameters.items():\n",
        "    for p in params:\n",
        "      p.grad = torch.zeros(1)"
      ],
      "metadata": {
        "id": "bggFCzpRMS4o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "986f108b-a2b6-4930-b8f0-f33888d50164"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: tensor([0.7671])\n",
            "1e-05\n",
            "output: tensor([-1.9539e-06], grad_fn=<NativeLayerNormBackward0>)\n",
            "Value norm_0 [tensor([1.]), tensor([0.])]\n",
            "Grad norm_0 [tensor([-1.9539e-06]), tensor([1.])]\n",
            "\n",
            "input: tensor([0.6408])\n",
            "1e-05\n",
            "output: tensor([1.3551e-06], grad_fn=<NativeLayerNormBackward0>)\n",
            "Value norm_0 [tensor([1.]), tensor([0.])]\n",
            "Grad norm_0 [tensor([1.3551e-06]), tensor([1.])]\n",
            "\n",
            "input: tensor([0.5456])\n",
            "1e-05\n",
            "output: tensor([-7.1208e-06], grad_fn=<NativeLayerNormBackward0>)\n",
            "Value norm_0 [tensor([1.]), tensor([0.])]\n",
            "Grad norm_0 [tensor([-7.1208e-06]), tensor([1.])]\n",
            "\n",
            "input: tensor([0.3546])\n",
            "1e-05\n",
            "output: tensor([1.0027e-06], grad_fn=<NativeLayerNormBackward0>)\n",
            "Value norm_0 [tensor([1.]), tensor([0.])]\n",
            "Grad norm_0 [tensor([1.0027e-06]), tensor([1.])]\n",
            "\n",
            "input: tensor([0.0453])\n",
            "1e-05\n",
            "output: tensor([4.0325e-07], grad_fn=<NativeLayerNormBackward0>)\n",
            "Value norm_0 [tensor([1.]), tensor([0.])]\n",
            "Grad norm_0 [tensor([4.0325e-07]), tensor([1.])]\n",
            "\n"
          ]
        }
      ]
    }
  ]
}